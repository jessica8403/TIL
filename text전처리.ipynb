{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text전처리.ipynb",
      "provenance": [],
      "mount_file_id": "1pwvPo3XPU_0xXnlMxKEbEXVsSz191Pl2",
      "authorship_tag": "ABX9TyMIJQdrAzZmk5eAeMYkFb+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica8403/TIL/blob/master/text%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vXnmNObhUdM",
        "outputId": "7af9ec58-f4c0-4961-8af3-a84e9f354d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "9FvicJJUhaZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMR6wzxYhi0Z",
        "outputId": "2a8c6b88-93f5-4733-d0fe-8b30f509c068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.5 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 23.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "apt-get update\n",
        "apt-get install g++ openjdk-8-jdk python-dev python3-dev\n",
        "pip install JPype1\n",
        "pip install konlpy"
      ],
      "metadata": {
        "id": "5m0Na-gn6O46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WePpcuA6XIQ",
        "outputId": "7c1d6648-9823-4037-aa8a-8a705ac35ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
        "pip install /tmp/mecab-python-0.996"
      ],
      "metadata": {
        "id": "fYIE92Ua6X44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Kkma, Komoran, Okt, Hannanum, Mecab"
      ],
      "metadata": {
        "id": "23jM3kPQiY8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 교재에서는 실습을 위해서\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']"
      ],
      "metadata": {
        "id": "h14eneXViy8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "XgyagpfH0u1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 객체 생성(가장 빈도가 높은 단어 1,000개만 선택해서 토크나이징)\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "\n",
        "# 단어 인덱스 구축\n",
        "tokenizer.fit_on_texts(samples)\n",
        "\n",
        "# 인덱스 리트스 확인\n",
        "sequence = tokenizer.texts_to_sequences(samples)\n",
        "print(sequence)\n",
        "\n",
        "# 변환된 숫자 인덱스를 벡터 형태로 변환()\n",
        "one_hot_encoded = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "print(one_hot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBh-1K-31-Qm",
        "outputId": "ddee9202-714e-4a87-a6ce-24ea37e52af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 1, 5], [1, 6, 7, 8, 9]]\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kkma = Kkma()\n",
        "komoran = Komoran()\n",
        "han = Hannanum()\n",
        "mecab = Mecab()\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "bWqnyMs32eCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = ['아버지가방에들어가신다', '아기다리고기다리던데이터']"
      ],
      "metadata": {
        "id": "bx8nMaCR5um_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kkma.pos(samples[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GZ55ttm8mSf",
        "outputId": "63baa968-1180-4443-b277-2fd12e33472f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('아버지', 'NNG'),\n",
              " ('가방', 'NNG'),\n",
              " ('에', 'JKM'),\n",
              " ('들어가', 'VV'),\n",
              " ('시', 'EPH'),\n",
              " ('ㄴ다', 'EFN')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kkma.morphs( samples[1] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_VGwcMI8q5B",
        "outputId": "7c3c89dc-f8df-4db6-8339-5db30b16538d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아', '아', '기다리', '고', '기다리', '던데', '이', '터']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kkma.nouns( samples[0] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kubWpBz_86-f",
        "outputId": "fbe42051-5ff9-40be-98bb-ccd1ae854c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아버지', '아버지가방', '가방']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mecab.pos( samples[0] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRYbK4569Irr",
        "outputId": "de745265-baf0-4656-a977-e7551fb91a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('아버지', 'NNG'),\n",
              " ('가', 'JKS'),\n",
              " ('방', 'NNG'),\n",
              " ('에', 'JKB'),\n",
              " ('들어가', 'VV'),\n",
              " ('신다', 'EP+EC')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mecab.morphs( samples[1] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjjYXEzB9SLi",
        "outputId": "35aa1282-a5c3-4da3-f9c2-22f62b307f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아기', '다리', '고', '기다리', '던', '데이터']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mecab.nouns( samples[1] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFDTRWGD9aOb",
        "outputId": "7b97bc4b-798e-4e2d-8ecf-54cf5747dd13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아기', '데이터']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "komoran.pos( samples[1] )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYt2yrNX9jof",
        "outputId": "ed4ea622-5bb0-4617-cb24-6744c8c9fc09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('아', 'IC'),\n",
              " ('기다리', 'VV'),\n",
              " ('고', 'EC'),\n",
              " ('기다리', 'VV'),\n",
              " ('던', 'ETM'),\n",
              " ('데이터', 'NNG')]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_to_word = []\n",
        "for sample in samples:\n",
        "  # print( mecab.morphs(sample) )\n",
        "  samples_to_word.append( mecab.morphs(sample) )\n",
        "\n",
        "samples_to_word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYtjObmm94EK",
        "outputId": "153c568e-f436-4125-de34-f68360108fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['아버지', '가', '방', '에', '들어가', '신다'], ['아기', '다리', '고', '기다리', '던', '데이터']]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "WcCYNEMqA3we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(samples_to_word)\n",
        "sequence = tokenizer.texts_to_sequences(samples_to_word)\n",
        "print(sequence) \n",
        "\n",
        "one_hot_encoded = tokenizer.texts_to_matrix(samples_to_word, mode='binary')\n",
        "print(one_hot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpacvexkBUw_",
        "outputId": "04ef0f1f-95eb-4cd3-9cb7-a04c1bd66e94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12]]\n",
            "[[0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb"
      ],
      "metadata": {
        "id": "WulIFeANBXiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 특성으로 사용할 단어의 갯수\n",
        "max_features = 10000\n",
        "# 사용할 텍스트의 길이\n",
        "maxLen = 20\n",
        "\n",
        "# 정수 리스트로 데이터를 로드\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
        "\n",
        "# 정수 리스트를 (samples, maxLen) 크기의 2D 정수 텐서로 변환\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)"
      ],
      "metadata": {
        "id": "saNwkbxREmeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "JmiXSglCGwLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxLen)\n",
        "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxLen)"
      ],
      "metadata": {
        "id": "mxGDWMzXGzuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWxWirYQFMgo",
        "outputId": "38a131fb-2b7b-4d9e-ee3c-6046668b3fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  65,   16,   38, ...,   19,  178,   32],\n",
              "       [  23,    4, 1690, ...,   16,  145,   95],\n",
              "       [1352,   13,  191, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11, 1818, 7561, ...,    4, 3586,    2],\n",
              "       [  92,  401,  728, ...,   12,    9,   23],\n",
              "       [ 764,   40,    4, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# 10000개의 단어에 대해서 8차원의 임베딩을 학습\n",
        "model.add( tf.keras.layers.Embedding(10000, 8, input_length=maxLen ) )\n",
        "\n",
        "# 3d 임베딩 벡터를 (samples, maxLen * 8 ) 크기의 2D 벡터로 변환\n",
        "model.add( tf.keras.layers.Flatten() )\n",
        "\n",
        "# 분류기 추가\n",
        "model.add( tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# 최적화 옵션\n",
        "model.compile(\n",
        "  loss = 'binary_crossentropy',\n",
        "  metrics = ['acc'],\n",
        "  optimizer = 'rmsprop'\n",
        ")"
      ],
      "metadata": {
        "id": "LlI-gVVzFr3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit( x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuUGsfS5IaiT",
        "outputId": "b9432fd5-a57e-4f82-cb80-4d8f65ef197d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 7s 7ms/step - loss: 0.6743 - acc: 0.6041 - val_loss: 0.6298 - val_acc: 0.6916\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.5510 - acc: 0.7477 - val_loss: 0.5328 - val_acc: 0.7292\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4655 - acc: 0.7863 - val_loss: 0.5038 - val_acc: 0.7438\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.4232 - acc: 0.8076 - val_loss: 0.4958 - val_acc: 0.7496\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3951 - acc: 0.8228 - val_loss: 0.4962 - val_acc: 0.7528\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3724 - acc: 0.8354 - val_loss: 0.4993 - val_acc: 0.7534\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3528 - acc: 0.8468 - val_loss: 0.5039 - val_acc: 0.7566\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3347 - acc: 0.8568 - val_loss: 0.5121 - val_acc: 0.7544\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3183 - acc: 0.8663 - val_loss: 0.5204 - val_acc: 0.7540\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 5ms/step - loss: 0.3025 - acc: 0.8756 - val_loss: 0.5288 - val_acc: 0.7502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dir_path = '/content/drive/MyDrive/멀티캠퍼스/data/IMDB'\n",
        "# file_path = '/content/drive/MyDrive/멀티캠퍼스/data/IMDB/aclImdb.zip'\n",
        "\n",
        "# # 압축이 풀리면 다음에 다시 압축을 풀지 않도록 주석으로 바꿔주도록 합니다.\n",
        "# %cd '{dir_path}'\n",
        "# !unzip '{file_path}'"
      ],
      "metadata": {
        "id": "Q-aJycj2IiVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/멀티캠퍼스/data/IMDB/aclImdb'\n",
        "\n",
        "file_path = os.path.join( dir_path, 'train/neg')\n",
        "file_name = os.listdir(file_path)[0]\n",
        "with open( os.path.join(file_path, file_name), 'r') as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "id": "kIgGCzfjPL5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe491f23-4e9c-4b75-a412-7d877cd26a92"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_path = '/content/drive/MyDrive/멀티캠퍼스/data/IMDB/aclImdb'\n",
        "train_dir_path = os.path.join( dir_path, 'train')\n",
        "\n",
        "labels = []\n",
        "texts = []\n",
        "\n",
        "for label_type in ['neg', 'pos']:\n",
        "  dir_name = os.path.join( train_dir_path, label_type )\n",
        "  for fname in os.listdir( dir_name ):\n",
        "    # 폴더 내에 .txt가 아닌 파일도 있는 것 같습니다.\n",
        "    if fname[-4:] == '.txt':\n",
        "      with open( os.path.join( dir_name, fname), 'r' ) as f:\n",
        "        texts.append( f.read() )\n",
        "      if label_type == 'neg': labels.append(0)\n",
        "      else: labels.append(1)"
      ],
      "metadata": {
        "id": "hTn7C2rpWjkZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIJdWxEBX05q",
        "outputId": "8563bd1e-b04f-455a-942f-02dc0f2c3f37"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\",\n",
              " \"Airport '77 starts as a brand new luxury 747 plane is loaded up with valuable paintings & such belonging to rich businessman Philip Stevens (James Stewart) who is flying them & a bunch of VIP's to his estate in preparation of it being opened to the public as a museum, also on board is Stevens daughter Julie (Kathleen Quinlan) & her son. The luxury jetliner takes off as planned but mid-air the plane is hi-jacked by the co-pilot Chambers (Robert Foxworth) & his two accomplice's Banker (Monte Markham) & Wilson (Michael Pataki) who knock the passengers & crew out with sleeping gas, they plan to steal the valuable cargo & land on a disused plane strip on an isolated island but while making his descent Chambers almost hits an oil rig in the Ocean & loses control of the plane sending it crashing into the sea where it sinks to the bottom right bang in the middle of the Bermuda Triangle. With air in short supply, water leaking in & having flown over 200 miles off course the problems mount for the survivor's as they await help with time fast running out...<br /><br />Also known under the slightly different tile Airport 1977 this second sequel to the smash-hit disaster thriller Airport (1970) was directed by Jerry Jameson & while once again like it's predecessors I can't say Airport '77 is any sort of forgotten classic it is entertaining although not necessarily for the right reasons. Out of the three Airport films I have seen so far I actually liked this one the best, just. It has my favourite plot of the three with a nice mid-air hi-jacking & then the crashing (didn't he see the oil rig?) & sinking of the 747 (maybe the makers were trying to cross the original Airport with another popular disaster flick of the period The Poseidon Adventure (1972)) & submerged is where it stays until the end with a stark dilemma facing those trapped inside, either suffocate when the air runs out or drown as the 747 floods or if any of the doors are opened & it's a decent idea that could have made for a great little disaster flick but bad unsympathetic character's, dull dialogue, lethargic set-pieces & a real lack of danger or suspense or tension means this is a missed opportunity. While the rather sluggish plot keeps one entertained for 108 odd minutes not that much happens after the plane sinks & there's not as much urgency as I thought there should have been. Even when the Navy become involved things don't pick up that much with a few shots of huge ships & helicopters flying about but there's just something lacking here. George Kennedy as the jinxed airline worker Joe Patroni is back but only gets a couple of scenes & barely even says anything preferring to just look worried in the background.<br /><br />The home video & theatrical version of Airport '77 run 108 minutes while the US TV versions add an extra hour of footage including a new opening credits sequence, many more scenes with George Kennedy as Patroni, flashbacks to flesh out character's, longer rescue scenes & the discovery or another couple of dead bodies including the navigator. While I would like to see this extra footage I am not sure I could sit through a near three hour cut of Airport '77. As expected the film has dated badly with horrible fashions & interior design choices, I will say no more other than the toy plane model effects aren't great either. Along with the other two Airport sequels this takes pride of place in the Razzie Award's Hall of Shame although I can think of lots of worse films than this so I reckon that's a little harsh. The action scenes are a little dull unfortunately, the pace is slow & not much excitement or tension is generated which is a shame as I reckon this could have been a pretty good film if made properly.<br /><br />The production values are alright if nothing spectacular. The acting isn't great, two time Oscar winner Jack Lemmon has said since it was a mistake to star in this, one time Oscar winner James Stewart looks old & frail, also one time Oscar winner Lee Grant looks drunk while Sir Christopher Lee is given little to do & there are plenty of other familiar faces to look out for too.<br /><br />Airport '77 is the most disaster orientated of the three Airport films so far & I liked the ideas behind it even if they were a bit silly, the production & bland direction doesn't help though & a film about a sunken plane just shouldn't be this boring or lethargic. Followed by The Concorde ... Airport '79 (1979).\"]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euFthI2rYPhI",
        "outputId": "bc59a98b-4d27-40ed-b83b-cddfe24c8eed"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F00_9QAEYRt0",
        "outputId": "43401df0-3988-4499-9e1f-94cf80d86bdd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "n-blROJ4YTlM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxLen = 100 # 100개의 단어만 사용\n",
        "max_words = 10000 # 주어진 학습 셋에서 빈도가 가장 높은 10000개의 단어만 사용\n",
        "\n",
        "training_samples = 200\n",
        "validation_samples = 10000 # 일부러 과적합 하려고 한 것 같습니다.\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequence = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# 정수 리스트를 (samples, maxLen) 크기의 2D 정수 텐서로 변환\n",
        "data = keras.preprocessing.sequence.pad_sequences( sequence, maxlen = maxLen )\n",
        "labels = np.asarray( labels )"
      ],
      "metadata": {
        "id": "yNaB1ckDd0oE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1t5WgJpeehO0",
        "outputId": "e92a8bf2-45bd-4b33-929f-28cbdb3524ca"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bfKG4_ueltq",
        "outputId": "cef91abd-0ecf-4a33-95e6-13b69785e977"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 부정 리뷰 이후에 긍정 리뷰가 이어지기 때문에\n",
        "# 샘플링 하기 위해서 데이터를 무작위로 섞은 이후에 200개의 샘플을 추출\n",
        "\n",
        "# 부정 리뷰 이후에 긍정 리뷰가 이어지기 때문에\n",
        "# 샘플링 하기 위해서 데이터를 무작위로 섞은 이후에 200개의 샘플을 추출\n",
        "\n",
        "# 전체 데이터의 개수만큼 수열을 생성\n",
        "indices = np.arange( data.shape[0] ) \n",
        "print( indices )\n",
        "\n",
        "# 생성된 수열을 섞어줍니다.\n",
        "np.random.shuffle( indices )\n",
        "print( indices )\n",
        "\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "# 학습자료와 검증 자료로 분할\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_validation = data[training_samples: training_samples + validation_samples]\n",
        "y_validation = labels[training_samples: training_samples + validation_samples]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNwGOxUGeoJ6",
        "outputId": "07a581c7-0d7d-49f7-bf77-dd3ee73039f8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0     1     2 ... 24997 24998 24999]\n",
            "[ 2073 17619 22198 ...  3774  5499  1155]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_validation.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8fFnlfcgK0L",
        "outputId": "8e374a8d-258e-456d-aee5-e01150178642"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 100)\n",
            "(10000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWaqeJH-gTPt",
        "outputId": "8ee40b4f-b35a-4120-8227-d857c30b55aa"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uXGjVBgcgeIX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}