{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessica8403/TIL/blob/master/%EC%A6%9D%EA%B0%95%EC%B5%9C%EC%A2%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3DEv6QSgWlJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU 할당\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXCdLRGu9m4Y"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jH_iQ9IV4zA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # GPU 할당"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L1HO70AhWDHd",
        "outputId": "85ae3742-8d91-4e26-cbc4-8589ad912af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ]
        }
      ],
      "source": [
        "#create training dataset\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "path = '/content/drive/MyDrive/멀티캠퍼스/data/train/'\n",
        "\n",
        "training_images = []\n",
        "training_labels = []\n",
        "\n",
        "for filename in glob(path +\"*\"):\n",
        "    for img in glob(filename + \"/*.jpg\"):\n",
        "        an_img = PIL.Image.open(img) #read img\n",
        "        img_array = np.array(an_img) #img to array\n",
        "        training_images.append(img_array) #append array to training_images\n",
        "        label = filename.split('/')[-2] #get label\n",
        "        training_labels.append(label) #append label\n",
        "        \n",
        "training_images = np.array(training_images)\n",
        "training_labels = np.array(training_labels)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "training_labels= le.fit_transform(training_labels)\n",
        "training_labels = training_labels.reshape(-1,1)\n",
        "\n",
        "print(training_images.shape)\n",
        "print(training_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGzeRy-1WP-2"
      },
      "outputs": [],
      "source": [
        "#create test dataset\n",
        "\n",
        "path = '/content/drive/MyDrive/멀티캠퍼스/data/test/'\n",
        "\n",
        "test_images = []\n",
        "test_idx = []\n",
        "\n",
        "flist = sorted(glob(path + '*.jpg'))\n",
        "\n",
        "for filename in flist:\n",
        "    an_img = PIL.Image.open(filename) #read img\n",
        "    img_array = np.array(an_img) #img to array\n",
        "    test_images.append(img_array) #append array to training_images \n",
        "    label = filename.split('/')[7] #get id \n",
        "    test_idx.append(label) #append id\n",
        "    \n",
        "test_images = np.array(test_images)\n",
        "\n",
        "print(test_images.shape)\n",
        "print(test_idx[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdH_mrpjWVv-"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(20):\n",
        "    plt.subplot(4, 5, i + 1)\n",
        "    plt.imshow(training_images[i*2500])\n",
        "    print(training_labels[i*2500], end=\",\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69eCNsdOWmsU"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "image_generator = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    brightness_range = [0.8, 1.0],\n",
        "    zoom_range=0.3,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ophk9JZqWpW9"
      },
      "outputs": [],
      "source": [
        "sample_image = training_images[1]\n",
        "plt.imshow(sample_image.astype('uint8'))\n",
        "sample_image = np.expand_dims(sample_image, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxV0CnCOWsHs"
      },
      "outputs": [],
      "source": [
        "sample_image_it = image_generator.flow(sample_image, batch_size=1, seed = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya-ae9LEWurX"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize = (10,10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, 1+i)\n",
        "    batch = sample_image_it.next()\n",
        "    image = batch[0].astype('uint8')\n",
        "    plt.imshow(image)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUKKXZ7LWwdC"
      },
      "outputs": [],
      "source": [
        "augment_size=150000\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "random_mask = np.random.randint(training_images.shape[0], size=augment_size)\n",
        "training_image_aug = training_images[random_mask].copy()\n",
        "training_labels_aug = training_labels[random_mask].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcbNbLaLWzDd"
      },
      "outputs": [],
      "source": [
        "training_image_aug = image_generator.flow(training_image_aug, np.zeros(augment_size), batch_size=augment_size, shuffle=False, seed = 42).next()[0]\n",
        "\n",
        "training_images = np.concatenate((training_images, training_image_aug))\n",
        "training_labels = np.concatenate((training_labels, training_labels_aug))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuwbnNDCW1dj"
      },
      "outputs": [],
      "source": [
        "print(training_images.shape)\n",
        "print(training_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Za6SkarW3a8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "sample_image = training_images[1]\n",
        "sample_label = tf.one_hot(training_labels[1], 10) # one hot encoding을 진행해야 mixup을 할 수 있습니다.\n",
        "\n",
        "sample_image2 = training_images[5001]\n",
        "sample_label2 = tf.one_hot(training_labels[5001], 10)\n",
        "\n",
        "fig = plt.figure(figsize = (8,8))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.imshow(sample_image.astype('uint8'))\n",
        "print(sample_label)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.imshow(sample_image2.astype('uint8'))\n",
        "print(sample_label2)\n",
        "    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KBcyljjW5um"
      },
      "outputs": [],
      "source": [
        "def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n",
        "    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n",
        "    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n",
        "    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n",
        "\n",
        "\n",
        "def mix_up(ds_one, ds_two, batch_size = 1, alpha=0.2):\n",
        "    # Unpack two datasets\n",
        "    images_one, labels_one = ds_one\n",
        "    images_two, labels_two = ds_two\n",
        "\n",
        "    # Sample lambda and reshape it to do the mixup\n",
        "    l = sample_beta_distribution(batch_size, alpha, alpha)\n",
        "    x_l = tf.reshape(l, (batch_size, 1, 1, 1))\n",
        "    y_l = tf.reshape(l, (batch_size, 1))\n",
        "\n",
        "    # Perform mixup on both images and labels by combining a pair of images/labels\n",
        "    # (one from each dataset) into one image/label\n",
        "    images = images_one * x_l + images_two * (1 - x_l)\n",
        "    labels = labels_one * y_l + labels_two * (1 - y_l)\n",
        "    return (images, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oh_LM-aLW8lw"
      },
      "outputs": [],
      "source": [
        "mix_image, mix_label = mix_up((sample_image, sample_label), (sample_image2, sample_label2), batch_size = 9, alpha = 0.5)\n",
        "\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "for i in range(9):\n",
        "    plt.subplot(3, 3, 1+i)\n",
        "    image = mix_image[i]\n",
        "    plt.imshow(image.numpy().squeeze().astype('uint8'))\n",
        "    print(mix_label[i].numpy().tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHyGLq6TW_WQ"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "from sys import stdout\n",
        "\n",
        "training_labels = tf.one_hot(training_labels, 10) #mixup을 적용하기 위해 one-hot 기법을 적용해줍니다\n",
        "\n",
        "mix_training_images = []\n",
        "mix_training_labels = []\n",
        "\n",
        "for i in range(3):\n",
        "    random_num = random.sample(range(0,50000), 50000) #augmentation을 적용한 데이터를 제외하고 mix해보겠습니다\n",
        "    print(\"\\nAttempt\", i)\n",
        "    progress_before = 0\n",
        "\n",
        "    for i in range(0,50000,2):\n",
        "        image_1 = training_images[random_num[i]]\n",
        "        label_1 = training_labels[random_num[i]]\n",
        "\n",
        "        image_2 = training_images[random_num[i+1]]\n",
        "        label_2 = training_labels[random_num[i+1]]\n",
        "\n",
        "        mix_image, mix_label = mix_up((image_1, label_1), (image_2, label_2))\n",
        "\n",
        "        mix_training_images.append(mix_image[0])\n",
        "        mix_training_labels.append(mix_label[0])\n",
        "        \n",
        "        #just for ui\n",
        "        progress = int(100*(i/49998))\n",
        "        if progress != progress_before:\n",
        "            progress_before = progress\n",
        "            stdout.write(\"\\r ========= %d%% completed =========\" %progress)\n",
        "            stdout.flush()\n",
        "\n",
        "mix_training_images = np.array(mix_training_images)\n",
        "mix_training_labels = np.array(mix_training_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XarqK8-1XDG8"
      },
      "outputs": [],
      "source": [
        "print('mix_train 크기:',mix_training_images.shape)\n",
        "print('mix_label 크기:',mix_training_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5pWz8YKXFCX"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_labels = np.array(training_labels)\n",
        "training_labels = training_labels.reshape(-1,10) #mixup에서 one-hot 기법을 적용했다면, shape을 바꿔줍니다.\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(training_images, \n",
        "                                                      training_labels, \n",
        "                                                      test_size=0.05, \n",
        "                                                      stratify = training_labels, \n",
        "                                                      random_state=42)\n",
        "\n",
        "X_train = np.concatenate((X_train, mix_training_images)) #mixup한 75000개의 데이터를 train set에 추가해줍니다\n",
        "y_train = np.concatenate((y_train, mix_training_labels))\n",
        "\n",
        "X_test = test_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRGY8FL1XLX0"
      },
      "outputs": [],
      "source": [
        "print('X_train 크기:',X_train.shape)\n",
        "print('y_train 크기:',y_train.shape)\n",
        "print('X_valid 크기:',X_valid.shape)\n",
        "print('y_valid 크기:',y_valid.shape)\n",
        "print('X_test  크기:',X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpU9KRZ_XNEc"
      },
      "outputs": [],
      "source": [
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid / 255.0\n",
        "X_test = X_test / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66vPwrpwXOwv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(2, 2, padding='SAME'), #pooling layer\n",
        "    \n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(2, 2, padding='SAME'), #pooling layer\n",
        "    \n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(2, 2, padding='SAME'), #pooling layer\n",
        "    \n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='SAME',input_shape=(32, 32, 3)), #cnn layer\n",
        "    tf.keras.layers.BatchNormalization(), #batch norm layer\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D(2, 2, padding='SAME'), #pooling layer\n",
        "    \n",
        "    tf.keras.layers.GlobalAveragePooling2D(), #pooling layer\n",
        "\n",
        "    tf.keras.layers.Dense(256, activation = 'relu'), #fully connected layer\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation = 'relu'), #fully connected layer\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation = 'softmax') # ouput layer\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeimNn6MXSgC"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_7EltkCXVMi"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvZoBr0TXX9f"
      },
      "outputs": [],
      "source": [
        "EPOCH = 32\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',  # 모니터 기준 설정 (val loss) \n",
        "                              patience=5,         # 5 Epoch동안 개선되지 않는다면 종료\n",
        "                             )\n",
        "\n",
        "reduceLR = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUAqCfjKXaze"
      },
      "outputs": [],
      "source": [
        "data = model.fit(X_train, \n",
        "                 y_train, \n",
        "                 validation_data=(X_valid, y_valid), \n",
        "                 epochs=EPOCH, \n",
        "                 batch_size=BATCH_SIZE, \n",
        "                 callbacks=[reduceLR, earlystopping],)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nte2J3c5Xc81"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plot\n",
        "\n",
        "plot.plot(data.history['accuracy'])\n",
        "plot.plot(data.history['val_accuracy'])\n",
        "plot.title('Model accuracy')\n",
        "plot.ylabel('Accuracy')\n",
        "plot.xlabel('Epoch')\n",
        "plot.legend(['Train', 'Test'], loc='upper left')\n",
        "plot.show()\n",
        "\n",
        "plot.plot(data.history['loss'])\n",
        "plot.plot(data.history['val_loss'])\n",
        "plot.title('Model loss')\n",
        "plot.ylabel('Loss')\n",
        "plot.xlabel('Epoch')\n",
        "plot.legend(['Train', 'Test'], loc='upper left')\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyHJ9dtWXfVo"
      },
      "outputs": [],
      "source": [
        "pred_proba = model.predict(X_test) \n",
        "\n",
        "pred_class = []\n",
        "\n",
        "for i in pred_proba:\n",
        "    pred = np.argmax(i)\n",
        "    pred_class.append(pred)\n",
        "    \n",
        "pred_class = le.inverse_transform(pred_class)\n",
        "pred_class[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg_oOBaIXhgS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/멀티캠퍼스/data/\")\n",
        "\n",
        "sample_submission.target = pred_class\n",
        "sample_submission.to_csv(\"submit_final.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFYJEQrfXjjD"
      },
      "outputs": [],
      "source": [
        "sample_submission.head(20)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "증강최종.ipynb",
      "provenance": [],
      "mount_file_id": "1fStZlISLYN8x6VFev3gV0XqGbvuL4HSP",
      "authorship_tag": "ABX9TyObs/tsUz+4zAyPpnm3QpL0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}